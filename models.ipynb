{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "dim = int(sqrt(len(df.columns)-1))\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_sample = 8\n",
    "sample = df.drop(columns='label').iloc[[ix_sample]].values.reshape(dim,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16c1f48a8d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBThB4Ii/EBQ/w9n8S0vWL63KQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16c1d2968d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "im = Image.fromarray(np.uint8(cm.gist_earth(sample)*255))\n",
    "imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_one_hot(data, nb_classes):\n",
    "    \"\"\"Convert an iterable of indices to one-hot encoded labels.\"\"\"\n",
    "    targets = np.array(data, dtype=np.int16).reshape(-1)\n",
    "    return np.eye(nb_classes,dtype=np.int8)[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "labels = df['label'].values\n",
    "labels, levels = pd.factorize(labels)\n",
    "classes = len(np.unique(labels))\n",
    "y = indices_to_one_hot(labels, classes)\n",
    "data = df.drop(columns=['label']).values\n",
    "x_train, x_test, y_train, y_test = train_test_split(data,y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31500\n",
      "10500\n",
      "31500\n",
      "10500\n",
      "classes: 10\n",
      "[1 0 4 7 3 5 8 9 2 6]\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "print(\"classes:\", classes)\n",
    "print(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31500, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### Simple NN\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "\n",
    "input_shape = x_train.shape[1]\n",
    "output_shape = y_train.shape[1]\n",
    "\n",
    "inputs = Input(shape=(input_shape,))\n",
    "dense1 = Dense(units=1000, activation='relu')(inputs)\n",
    "dense2 = Dense(units=1000, activation='sigmoid')(dense1)\n",
    "dense3 = Dense(units=1000, activation='sigmoid')(dense2)\n",
    "output = Dense(units=output_shape, activation='softmax')(dense3)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "lr = 1e-4\n",
    "adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 2,797,010\n",
      "Trainable params: 2,797,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31500 samples, validate on 10500 samples\n",
      "Epoch 1/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.9342 - acc: 0.7818Epoch 00001: val_acc improved from -inf to 0.90333, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 4s 114us/step - loss: 0.9254 - acc: 0.7837 - val_loss: 0.3861 - val_acc: 0.9033\n",
      "Epoch 2/100\n",
      "30464/31500 [============================>.] - ETA: 0s - loss: 0.2987 - acc: 0.9205Epoch 00002: val_acc improved from 0.90333 to 0.92895, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 53us/step - loss: 0.2981 - acc: 0.9204 - val_loss: 0.2609 - val_acc: 0.9290\n",
      "Epoch 3/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.2111 - acc: 0.9420Epoch 00003: val_acc improved from 0.92895 to 0.94095, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 52us/step - loss: 0.2104 - acc: 0.9422 - val_loss: 0.2064 - val_acc: 0.9410\n",
      "Epoch 4/100\n",
      "30720/31500 [============================>.] - ETA: 0s - loss: 0.1632 - acc: 0.9555Epoch 00004: val_acc improved from 0.94095 to 0.94933, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 52us/step - loss: 0.1634 - acc: 0.9553 - val_loss: 0.1774 - val_acc: 0.9493\n",
      "Epoch 5/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9645Epoch 00005: val_acc improved from 0.94933 to 0.95486, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 52us/step - loss: 0.1303 - acc: 0.9645 - val_loss: 0.1555 - val_acc: 0.9549\n",
      "Epoch 6/100\n",
      "30720/31500 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9717Epoch 00006: val_acc improved from 0.95486 to 0.95867, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 52us/step - loss: 0.1048 - acc: 0.9717 - val_loss: 0.1428 - val_acc: 0.9587\n",
      "Epoch 7/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9789Epoch 00007: val_acc improved from 0.95867 to 0.96181, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 52us/step - loss: 0.0841 - acc: 0.9786 - val_loss: 0.1280 - val_acc: 0.9618\n",
      "Epoch 8/100\n",
      "30720/31500 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9841Epoch 00008: val_acc improved from 0.96181 to 0.96400, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 52us/step - loss: 0.0675 - acc: 0.9840 - val_loss: 0.1199 - val_acc: 0.9640\n",
      "Epoch 9/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9877Epoch 00009: val_acc improved from 0.96400 to 0.96657, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 51us/step - loss: 0.0541 - acc: 0.9877 - val_loss: 0.1142 - val_acc: 0.9666\n",
      "Epoch 10/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9902Epoch 00010: val_acc improved from 0.96657 to 0.96714, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 51us/step - loss: 0.0452 - acc: 0.9903 - val_loss: 0.1089 - val_acc: 0.9671\n",
      "Epoch 11/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9927Epoch 00011: val_acc did not improve\n",
      "31500/31500 [==============================] - 2s 51us/step - loss: 0.0380 - acc: 0.9926 - val_loss: 0.1062 - val_acc: 0.9664\n",
      "Epoch 12/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9951Epoch 00012: val_acc improved from 0.96714 to 0.96819, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 52us/step - loss: 0.0284 - acc: 0.9950 - val_loss: 0.1039 - val_acc: 0.9682\n",
      "Epoch 13/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9970Epoch 00013: val_acc improved from 0.96819 to 0.96905, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 51us/step - loss: 0.0212 - acc: 0.9969 - val_loss: 0.1015 - val_acc: 0.9690\n",
      "Epoch 14/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9980Epoch 00014: val_acc improved from 0.96905 to 0.96981, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 51us/step - loss: 0.0161 - acc: 0.9980 - val_loss: 0.0988 - val_acc: 0.9698\n",
      "Epoch 15/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9985Epoch 00015: val_acc improved from 0.96981 to 0.97029, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 51us/step - loss: 0.0126 - acc: 0.9986 - val_loss: 0.0978 - val_acc: 0.9703\n",
      "Epoch 16/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9990Epoch 00016: val_acc improved from 0.97029 to 0.97076, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 51us/step - loss: 0.0098 - acc: 0.9990 - val_loss: 0.0975 - val_acc: 0.9708\n",
      "Epoch 17/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9992Epoch 00017: val_acc did not improve\n",
      "31500/31500 [==============================] - 2s 50us/step - loss: 0.0080 - acc: 0.9991 - val_loss: 0.0974 - val_acc: 0.9703\n",
      "Epoch 18/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9993Epoch 00018: val_acc improved from 0.97076 to 0.97086, saving model to NN/weights.hdf5\n",
      "31500/31500 [==============================] - 2s 51us/step - loss: 0.0067 - acc: 0.9993 - val_loss: 0.0975 - val_acc: 0.9709\n",
      "Epoch 19/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9995Epoch 00019: val_acc did not improve\n",
      "31500/31500 [==============================] - 2s 50us/step - loss: 0.0057 - acc: 0.9995 - val_loss: 0.0975 - val_acc: 0.9707\n",
      "Epoch 20/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9996Epoch 00020: val_acc did not improve\n",
      "31500/31500 [==============================] - 2s 50us/step - loss: 0.0050 - acc: 0.9996 - val_loss: 0.0976 - val_acc: 0.9707\n",
      "Epoch 21/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9997Epoch 00021: val_acc improved from 0.97086 to 0.97162, saving model to NN/weights.hdf5\n",
      "\n",
      "Epoch 00021: reducing learning rate to 3.2999999166349884e-05.\n",
      "31500/31500 [==============================] - 2s 52us/step - loss: 0.0044 - acc: 0.9997 - val_loss: 0.0977 - val_acc: 0.9716\n",
      "Epoch 22/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9996Epoch 00022: val_acc did not improve\n",
      "31500/31500 [==============================] - 2s 50us/step - loss: 0.0039 - acc: 0.9997 - val_loss: 0.0982 - val_acc: 0.9713\n",
      "Epoch 23/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9997Epoch 00023: val_acc did not improve\n",
      "31500/31500 [==============================] - 2s 50us/step - loss: 0.0037 - acc: 0.9997 - val_loss: 0.0982 - val_acc: 0.9715\n",
      "Epoch 24/100\n",
      "30720/31500 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9996Epoch 00024: val_acc did not improve\n",
      "\n",
      "Epoch 00024: reducing learning rate to 1.0890000085055363e-05.\n",
      "31500/31500 [==============================] - 2s 50us/step - loss: 0.0039 - acc: 0.9997 - val_loss: 0.0985 - val_acc: 0.9714\n",
      "Epoch 25/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9997Epoch 00025: val_acc did not improve\n",
      "31500/31500 [==============================] - 2s 51us/step - loss: 0.0034 - acc: 0.9997 - val_loss: 0.0985 - val_acc: 0.9713\n",
      "Epoch 26/100\n",
      "30976/31500 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9998Epoch 00026: val_acc did not improve\n",
      "31500/31500 [==============================] - 2s 50us/step - loss: 0.0034 - acc: 0.9998 - val_loss: 0.0985 - val_acc: 0.9713\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "path = 'NN'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "checkpoint = ModelCheckpoint(path+'/weights.hdf5', monitor='val_acc', verbose=2, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping(monitor='val_loss',patience=9, verbose = 1)\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss',factor=0.33,patience=3,verbose = 1)\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, \n",
    "                    callbacks = [checkpoint, early_stopping, reduceLR],validation_data=(x_test, y_test), class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_file = path + '/weights.hdf5'\n",
    "model.load_weights(weight_file)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some visual testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1147    0    2    3    3    1    5    2    3    0]\n",
      " [   0 1044    2    0    2    3    5    0    3    1]\n",
      " [   3    1 1023    2    0    0    1    8    2    4]\n",
      " [   1    3    7 1047    1    1    2    5    5    2]\n",
      " [   4    4    0    2 1048   13   10    3    8    1]\n",
      " [   1    4    2    1   17  855    6    6    2    3]\n",
      " [   2    4    4    3   11    7  994    4    1    6]\n",
      " [   2    4   11   10    9    5    4 1032    0    1]\n",
      " [   2    1    4    8    5    0    2    1 1011    3]\n",
      " [   0    3    3    1    0    4    2    0    1 1001]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1166\n",
      "           1       0.98      0.98      0.98      1060\n",
      "           2       0.97      0.98      0.97      1044\n",
      "           3       0.97      0.97      0.97      1074\n",
      "           4       0.96      0.96      0.96      1093\n",
      "           5       0.96      0.95      0.96       897\n",
      "           6       0.96      0.96      0.96      1036\n",
      "           7       0.97      0.96      0.96      1078\n",
      "           8       0.98      0.97      0.98      1037\n",
      "           9       0.98      0.99      0.98      1015\n",
      "\n",
      "    accuracy                           0.97     10500\n",
      "   macro avg       0.97      0.97      0.97     10500\n",
      "weighted avg       0.97      0.97      0.97     10500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
